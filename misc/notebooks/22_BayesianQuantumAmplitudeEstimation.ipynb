{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac8d53e0",
   "metadata": {},
   "source": [
    "# Bayesian Quantum Amplitude Estimation (BAYESQAE) module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb91ed55",
   "metadata": {},
   "source": [
    "The present notebook reviews the **Bayesian Quantum Amplitude Estimation (BAYESQAE)** algorithm.\n",
    "\n",
    "The **BAYESQAE** algorithm was implemented into the module *bayesian_ae* of the package *AE* of the library *QQuantLib* (**QQuantLib/AE/bayesian_ae.py**). This algorithm is encapsulated in a Python class called `BAYESQAE`.\n",
    "\n",
    "The present notebook and modules are based on the following reference:\n",
    "\n",
    "- Alexandra RamÃ´a and Luis Paulo Santos . Bayesian Quantum Amplitude Estimation. https://arxiv.org/abs/2412.04394 (2024).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0ab600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0f929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## QPU\n",
    "from QQuantLib.qpu.get_qpu import get_qpu\n",
    "my_qpus = [\"python\", \"c\", \"qlmass_linalg\", \"qlmass_mps\", \"linalg\", \"mps\"]\n",
    "linalg_qpu = get_qpu(my_qpus[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584d84ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QQuantLib.DL.data_loading import load_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23c4a95",
   "metadata": {},
   "source": [
    "## 1. Oracle generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f851d971",
   "metadata": {},
   "source": [
    "Before performing any amplitude estimation, we need to load some data into the quantum circuit. Since this step is auxiliary and intended to illustrate how the algorithm works, we will simply load a discrete probability distribution. In this case, we will use a circuit with $ n = 3 $ qubits, resulting in a total of $ N = 2^n = 8 $ states. The discrete probability distribution we will load is defined as:\n",
    "\n",
    "$$\n",
    "p_d = \\frac{(0, 1, 2, 3, 4, 5, 6, 7)}{0 + 1 + 2 + 3 + 4 + 5 + 6 + 7}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e546068",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qbits = 3\n",
    "x = np.arange(2**n_qbits)\n",
    "probability = x/np.sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df53a96",
   "metadata": {},
   "source": [
    "Note that this probability distribution is properly normalized. To load this probability distribution into the quantum circuit, we will use the `load_probability` function from the **QQuantLib/DL/data_loading** module. The resulting quantum state can be expressed as:\n",
    "\n",
    "$$\n",
    "|\\Psi\\rangle = \\frac{1}{\\sqrt{0 + 1 + 2 + 3 + 4 + 5 + 6 + 7}} \\left[ \\sqrt{0}|0\\rangle + \\sqrt{1}|1\\rangle + \\sqrt{2}|2\\rangle + \\sqrt{3}|3\\rangle + \\sqrt{4}|4\\rangle + \\sqrt{5}|5\\rangle + \\sqrt{6}|6\\rangle + \\sqrt{7}|7\\rangle \\right].\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaed4936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QQuantLib.DL.data_loading import load_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd4552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = load_probability(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4cc5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%qatdisplay oracle --depth 1 --svg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae9391a",
   "metadata": {},
   "source": [
    "For more information on loading data into the quantum circuit, see the notebook `01_DataLoading_Module_Use.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2f075d",
   "metadata": {},
   "source": [
    "## 2. BAYESQAE algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89427b48",
   "metadata": {},
   "source": [
    "### 2.1 The Amplitude Estimation Problem\n",
    "\n",
    "The problem of amplitude estimation can be stated as follows. Given an oracle operator $\\mathcal{A}$:\n",
    "$$\n",
    "\\mathcal{A}|0\\rangle = |\\Psi\\rangle = \\sqrt{a}|\\Psi_0\\rangle + \\sqrt{1-a}|\\Psi_1\\rangle,\n",
    "$$\n",
    "where $|\\Psi_0\\rangle$ and $|\\Psi_1\\rangle$ are orthogonal states, the goal is to estimate the value of $\\sqrt{a}$. We can associate an angle $\\theta$ with $\\sqrt{a}$ such that $\\sin^2{\\theta} = a$, rewriting the problem as:\n",
    "$$\n",
    "\\mathcal{A}|0\\rangle = |\\Psi\\rangle = \\sin(\\theta)|\\Psi_0\\rangle + \\cos(\\theta)|\\Psi_1\\rangle. \\tag{1}\n",
    "$$\n",
    "\n",
    "The foundation of any amplitude estimation algorithm lies in the Grover-like operator $\\mathcal{Q}$ derived from the oracle operator $\\mathcal{A}$:\n",
    "$$\n",
    "\\mathcal{Q}(\\mathcal{A}) = \\mathcal{A} \\left(\\hat{I} - 2|0\\rangle\\langle 0|\\right) \\mathcal{A}^\\dagger \\left(\\hat{I} - 2|\\Psi_0\\rangle\\langle \\Psi_0|\\right).\n",
    "$$\n",
    "This operator acts on the state $|\\Psi\\rangle$ as follows:\n",
    "$$\n",
    "\\mathcal{Q}^{m_k}|\\Psi\\rangle = \\mathcal{Q}^{m_k} \\mathcal{A} |0\\rangle = \\sin\\left((2m_k+1)\\theta\\right)|\\Psi_0\\rangle + \\cos\\left((2m_k+1)\\theta\\right)|\\Psi_1\\rangle.\n",
    "$$\n",
    "\n",
    "For more information about the Grover operator and the amplitude amplification algorithm, refer to the notebook `02_AmplitudeAmplification_Operators.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e1a040",
   "metadata": {},
   "source": [
    "### 2.2 BAYESQAE Algorithm Summary\n",
    "\n",
    "Given an error tolerance $\\epsilon$ and a confidence level $\\alpha$, the **BAYESQAE** algorithm estimates an interval $(a_l, a_u)$ such that the parameter $a$ in the Amplitude Estimation problem satisfies:\n",
    "$$\n",
    "P\\big[a \\in [a_l, a_u]\\big] > 1 - \\alpha,\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\frac{a_u - a_l}{2} \\leq \\epsilon.\n",
    "$$\n",
    "\n",
    "To achieve this estimation, the **BAYESQAE** algorithm combines quantum Grover-like circuits ($\\mathcal{Q}^{m_k}|\\Psi\\rangle$) with a statistical inference framework. The core idea is to start with a prior probability distribution for the value of $a$, and then update it iteratively using the **Bayes rule**, based on the measurement outcomes of $\\mathcal{Q}^{m_k}|\\Psi\\rangle$. When the algorithm terminates, the value of $a$ can be estimated using the final posterior probability distribution.\n",
    "\n",
    "For the statistical inference, the **BAYESQAE** algorithm operates within the framework of **Sequential Monte Carlo (SMC)** methods. The goal is to use SMC to compute an optimal control for the next **Quantum Amplitude Estimation (QAE)** experiment (i.e., the choice of $m_k$ for the Grover circuit), given the current probability distribution and the results of previous QAE experiments. \n",
    "\n",
    "The computation of the optimal control involves minimizing a function called the **Utility of an experiment** over a dynamically evolving range of possible controls (i.e., $m_k$ for the Grover circuits)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25e272f",
   "metadata": {},
   "source": [
    "### 2.3 Creating an Object from the BAYESQAE Class\n",
    "\n",
    "We have implemented a Python class called `BAYESQAE` in the **QQuantLib/AE/bayesian_ae** module, which enables the use of the **BAYESQAE** algorithm. To create an instance of the **BAYESQAE** class, the conventions used in the **MLAE** class (from the **QQuantLib/AE/maximum_likelihood_ae** module) should be followed.\n",
    "\n",
    "#### Mandatory Inputs:\n",
    "1. `Oracle`: A myQLM AbstractGate or QRoutine object that implements the oracle for constructing the Grover operator.\n",
    "2. `Target`: The marked state in binary representation, provided as a Python list.\n",
    "3. `Index`: A list of qubits affected by the Grover operator.\n",
    "\n",
    "Several additional inputs can be provided as keyword arguments (using a Python dictionary) to configure different parts of the algorithm.\n",
    "\n",
    "---\n",
    "\n",
    "#### Quantum Parts Configuration:\n",
    "The following arguments can be used to configure the quantum components of the algorithm:\n",
    "- `qpu`: The myQLM solver to be used.\n",
    "- `mcz_qlm`: A boolean flag indicating whether to use the myQLM multi-controlled Z gate (`True`, default) or a multiplexor implementation (`False`).\n",
    "\n",
    "---\n",
    "\n",
    "#### Stopping Condition:\n",
    "The stopping condition for the **BAYESQAE** algorithm loop is controlled by the following keywords:\n",
    "- `epsilon` ($\\epsilon$): The precision parameter. Ensures that $|a_u - a_l|$ is at most $2\\epsilon$.\n",
    "- `alpha` ($\\alpha$): The accuracy parameter. Ensures that the probability of $a$ lying outside the given $\\epsilon$ interval is at most $\\alpha$ (default: 0.05).\n",
    "- `max_iterations`: The maximum number of iterations for the **BAYESQAE** algorithm loop. If the algorithm does not satisfy the $\\epsilon$ and $\\alpha$ requirements within this limit, the loop is truncated.\n",
    "\n",
    "---\n",
    "\n",
    "#### Sequential Monte Carlo (SMC) Method Configuration:\n",
    "The following keywords can be used to configure the SMC method used in the **BAYESQAE** algorithm:\n",
    "- `particles`: The number of particles used for executing the SMC simulation.\n",
    "- `threshold`: A float (between 0 and 1) that defines the threshold for triggering resampling of the SMC probability distribution.\n",
    "- `kernel`: A string specifying the type of perturbation kernel used during resampling. Options are:\n",
    "  - `LW`: Liu-West perturbation kernel.\n",
    "  - `Metro`: Metropolis perturbation kernel.\n",
    "- `alpha_lw`: A float between 0 and 1 for configuring the Liu-West perturbation kernel (used when `kernel=\"LW\"`).\n",
    "- `c`: A float for configuring the Metropolis perturbation kernel (used when `kernel=\"Metro\"`).\n",
    "\n",
    "---\n",
    "\n",
    "#### Dynamic Evolution of Control Domains:\n",
    "The following keywords can be used to configure the dynamic evolution of the domain controls for minimizing the **Utility of an experiment** function:\n",
    "- `n_evals`: The number of evaluations for optimizing the expected value of the utility function.\n",
    "- `k_0`: Together with `n_evals`, defines the upper limit for the initial domain interval for control optimization.\n",
    "- `R`: when the optimal control is among the top `R` highest possible controls then it can be necessary to enlarge the domain for the controls. An internal counter is increased by one when this happens.\n",
    "- `T`: If the optimal control is among the top `R` highest possible controls during `T` iterations, the domain interval for control optimization is enlarged (when the internal counter hits `T`)\n",
    "\n",
    "---\n",
    "\n",
    "#### Utility Function:\n",
    "\n",
    "\n",
    "In the original **BAYESQAE** paper, the **Utility of an experiment** function for minimization uses as base function the *variance* (in fact the expected value of the variance). By default, the function `variance_function` from the **QQuantLib/AE/bayesian_ae** module is used. To use a user-defined utility function, the following keyword can be provided:\n",
    "- `utility_function`: A Python function used for computing the **Utility of an experiment** for the **BAYESQAE** algorithm. The default is the variance function. A custom *utility function* must accept two numpy arrays as inputs:\n",
    "  - The first array contains the values of the SMC probability distribution.\n",
    "  - The second array contains the corresponding weights.\n",
    "  Additionally, the function may accept a `kwargs` argument.\n",
    "\n",
    "---\n",
    "\n",
    "#### Shots Configuration:\n",
    "The **BAYESQAE** algorithm requires performing virtual QAE experiments and updating probabilities using Bayes' rule. The number of shots for these tasks can be configured using the following keywords:\n",
    "- `shots`: The number of shots used for measuring the quantum part of the algorithm (this is the number of shots used for the complete Grover circuit). Default in the original paper: 1.\n",
    "- `warm_shots`: The number of shots selected for the warm-up phase (when the number of Grover operator applications is 0). Default in the original paper: 10.\n",
    "- `bayes_shots`: The number of shots used for Bayesian computations required to update the SMC prior probability distribution to the posterior one. Default in the original paper: 1.\n",
    "- `control_bayes_shots`: The number of shots used for updating the SMC posterior probabilities during optimization computations.\n",
    "\n",
    "---\n",
    "\n",
    "#### Fake Simulation Configuration:\n",
    "For very low $\\epsilon$, the number of Grover operator applications can become prohibitively large, making quantum circuit simulation unfeasible. In such cases, a fake simulation can be used, where **QAE** experiment results are sampled from a binomial distribution with the appropriate probability. The following keywords enable this fake simulation:\n",
    "- `fake`: A boolean flag. If `False`, the quantum circuit is used for the quantum part of the algorithm. If `True`, the quantum circuit is simulated by sampling from a binomial distribution (the true $\\theta$ must be provided).\n",
    "- `theta_good`: A float representing the true $\\theta$ value for fake simulations (i.e., random binomial sampling).\n",
    "\n",
    "---\n",
    "\n",
    "#### Other Configuration:\n",
    "Additional configuration options include:\n",
    "- `save_smc_prob`: An integer setting the frequency (in number of iterations) for storing the SMC probabilities.\n",
    "- `print_info`: An integer setting the frequency (in number of iterations) for printing information about the algorithm's evolution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf7dbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the class\n",
    "from QQuantLib.AE.bayesian_ae import BAYESQAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86496b9",
   "metadata": {},
   "source": [
    "### 2.4 Toy problem\n",
    "\n",
    "To show how our class and the algorithm work, we will define the following amplitude estimation problem using the generated oracle operator $\\mathcal{A}$ (see Section 2.1)\n",
    "\n",
    "$$|\\Psi\\rangle = \\mathcal{A}|0\\rangle = \\dfrac{1}{\\sqrt{0+1+2+3+4+5+6+7+8}}\\left[\\sqrt{0}|0\\rangle+\\sqrt{1}|1\\rangle+\\sqrt{2}|2\\rangle+\\sqrt{3}|3\\rangle+\\sqrt{4}|4\\rangle+\\sqrt{5}|5\\rangle+\\sqrt{6}|6\\rangle+\\sqrt{7}|7\\rangle\\right] \\tag{2}$$\n",
    "\n",
    "So comparing (2) with (1):\n",
    "\n",
    "$$\\sqrt{a}|\\Psi_0\\rangle = \\sin(\\theta)|\\Psi_0\\rangle = \\dfrac{\\sqrt{1}}{\\sqrt{0+1+2+3+4+5+6+7+8}}|1\\rangle$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\\sqrt{1-a}|\\Psi_1\\rangle = \\cos(\\theta)|\\Psi_1\\rangle = \\dfrac{1}{\\sqrt{0+1+2+3+4+5+6+7+8}}\\left[\\sqrt{0}|0\\rangle+\\sqrt{2}|2\\rangle+\\sqrt{3}|3\\rangle+\\sqrt{4}|4\\rangle+\\sqrt{5}|5\\rangle+\\sqrt{6}|6\\rangle+\\sqrt{7}|7\\rangle\\right].$$\n",
    "\n",
    "The target state, in this case, is $|1\\rangle$. In order to provide a binary representation the `bitfield` function from **QQuantLib.utils.utils** can be used. This has to be passed to the `target` variable as a list. Moreover, we have to provide the list of qubits where we are acting (to the `index` variable), in this case is just the whole register."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79c857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QQuantLib.utils.utils import bitfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6656dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [i for i in range(oracle.arity)]\n",
    "# Qubits where the operator should acts\n",
    "print(\"Operator should act over the following qubits: {}\".format(index))\n",
    "# Definition of the state\n",
    "state = 1\n",
    "# State conversion to binary representation\n",
    "target = bitfield(state, n_qbits)\n",
    "print(\"State: |{}>. Corresponding target:  {}\".format(state, target))\n",
    "# Probability and theta that we want ot estiamte\n",
    "a_good = probability[state]\n",
    "theta_good = np.arcsin(np.sqrt(a_good))\n",
    "print('Real Value of a: ', a_good)\n",
    "print('theta_good: ', theta_good)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3108b8f",
   "metadata": {},
   "source": [
    "Now that we have the mandatory inputs for instantiating the `BAYESQAE` class (the `oracle`, the `target`, and the `index`), we can proceed to configure the **BAYESQAE** algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f8c574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shots\n",
    "shots = 1\n",
    "#Stoping condition of the algorithm\n",
    "epsilon = 1.0e-4\n",
    "alpha = 0.05\n",
    "\n",
    "bayes_conf = {\n",
    "    # Quantum parts related\n",
    "    'qpu': linalg_qpu,\n",
    "    'mcz_qlm': True,\n",
    "    # Stoping condition\n",
    "    \"epsilon\" : epsilon,\n",
    "    \"alpha\": alpha,\n",
    "    \"max_iterations\": 1000,\n",
    "    # Configuration of the SMC method\n",
    "    \"particles\": 2000,      \n",
    "    \"threshold\": 0.5,    \n",
    "    \"kernel\" : \"LW\", #\"Metro\", #LW\n",
    "    \"alpha_lw\":0.9, # Liu-West kernel configuration\n",
    "    \"c\" : 2.38,   # Metropoli kernel configuration \n",
    "    # Dinamyc evolution of the domain controls\n",
    "    \"k_0\":2, \n",
    "    \"T\" : 3,\n",
    "    \"R\" : 3,    \n",
    "    \"n_evals\" : 50,    \n",
    "    # Shots configuration\n",
    "    \"shots\" : shots,\n",
    "    \"warm_shots\":10,\n",
    "    \"bayes_shots\": shots,\n",
    "    \"control_bayes_shots\" : shots,\n",
    "    # Fake configuration\n",
    "    \"fake\": False,\n",
    "    \"theta_good\": theta_good,    \n",
    "    # Other configuration\n",
    "    \"save_smc_prob\" : 1,\n",
    "    \"print_info\" : 1,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b73625",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate the Class\n",
    "bayes = BAYESQAE(\n",
    "    oracle,\n",
    "    target=target,\n",
    "    index=index,\n",
    "    **bayes_conf\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0bdd34",
   "metadata": {},
   "source": [
    "### 2.5 BAYESQAE Workflow\n",
    "\n",
    "In this section, we explain the workflow of the **BAYESQAE** algorithm using the `BAYESQAE` class and other implemented functions from the **QQuantLib/AE/bayesian_ae** module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a67331",
   "metadata": {},
   "source": [
    "#### 2.5.1 Building the SMC Prior Probability Distribution\n",
    "\n",
    "The first step in the **BAYESQAE** algorithm is to construct the prior probability distribution. In **Sequential Monte Carlo (SMC)** methods, the probability distribution is represented by two arrays:\n",
    "- One array contains the possible values of the parameter to be estimated: $\\{\\theta^{prior}_i\\}$.\n",
    "- The second array contains the corresponding weights: $\\{W^{prior}_i\\}$, which depend on the desired prior probability distribution.\n",
    "\n",
    "The weights **must** be normalized such that:\n",
    "$$\n",
    "\\sum_i W^{prior}_i = 1.\n",
    "$$\n",
    "\n",
    "The index $i$ runs from 1 to the desired number of particles, which is an input parameter of the algorithm (`particles`).\n",
    "\n",
    "Typically, a uniform prior probability distribution is used unless prior knowledge about the parameter suggests otherwise. In our implementation, we always start with a uniform probability distribution for the $\\theta$ value to estimate (recall that $\\sin^2{\\theta} = a$) over the interval $\\left[0, \\frac{\\pi}{2}\\right]$.\n",
    "\n",
    "The following cell builds the **SMC** prior probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7a0ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the particles attribute of the class\n",
    "theta_prior = np.random.uniform(0.0, 0.5 * np.pi, bayes.particles)\n",
    "# All the particles will have associated the same weights\n",
    "weights_prior = np.ones(len(theta_prior)) / len(theta_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee5a19b",
   "metadata": {},
   "source": [
    "#### 2.5.2 Warm-Up Measurement\n",
    "\n",
    "The second step in the **BAYESQAE** algorithm is the warm-up phase. During this phase, we measure the bare oracle operator $\\mathcal{A}$ to obtain initial results. This is achieved using the `quantum_measure_step` method of the **BAYESQAE** object.\n",
    "\n",
    "To perform this measurement, we need to specify:\n",
    "- The number of controls, $m_k$, which should be set to 0 during the warm-up phase.\n",
    "- The number of shots for measuring the circuit, which is determined by the `warm_shots` input parameter.\n",
    "\n",
    "The output of this step is the probability of measuring the *target* state. Additionally, the method provides the quantum circuit used for the measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6507a41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_0 = 0\n",
    "warm_outcome, routine = bayes.quantum_measure_step(m_0, bayes.warm_shots)\n",
    "print(\"Probability measured for warm up phase: {}\".format(warm_outcome))\n",
    "# Transform to measures\n",
    "warm_outcome = round(warm_outcome * bayes.warm_shots)\n",
    "print(\"Measured events for warm up phase: {}\".format(warm_outcome))\n",
    "\n",
    "# For storing all QAE experiments\n",
    "control_list = []\n",
    "shots_list = []\n",
    "outcome_list = []\n",
    "\n",
    "control_list.append(m_0)\n",
    "shots_list.append(bayes.warm_shots)\n",
    "outcome_list.append(warm_outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df58264",
   "metadata": {},
   "source": [
    "#### 2.5.3 Updating the SMC Posterior Probability with Warm-Up Results\n",
    "\n",
    "After obtaining the results from the warm-up **QAE** experiment, we update the prior probability distribution to the posterior probability using Bayes' theorem. This can be achieved using the `bayesian_update` function from the **QQuantLib/AE/bayesian_ae** module.\n",
    "\n",
    "This function accepts the following arguments:\n",
    "- `thetas`: The values of the SMC prior distribution ($\\{\\theta^{prior}_i\\}$).\n",
    "- `weights`: The weights of the SMC prior distribution ($\\{W^{prior}_i\\}$).\n",
    "- `m_k`: A list of all the controls used in the **QAE** experiments up to this point.\n",
    "- `n_k`: A list of all the shots used in the **QAE** experiments up to this point.\n",
    "- `o_k`: A list of all the outcomes obtained from the **QAE** experiments up to this point.\n",
    "- `resample`: A boolean flag indicating whether resampling should be performed.\n",
    "- `kwargs`: Additional arguments for configuring the resampling kernels.\n",
    "\n",
    "The workflow of the `bayesian_update` function is as follows:\n",
    "\n",
    "1. **Compute New Weights Using the Last QAE Experiment**:\n",
    "   - For each possible value of $\\theta$ in the input prior distribution, compute the likelihood based on the result of the last **QAE** experiment:\n",
    "     $$\n",
    "     L(\\theta | h_k; m_k, n_k) = \\sin^2\\left((2m_k+1)\\theta\\right)^{h_k} \\cos^2\\left((2m_k+1)\\theta\\right)^{n_k-h_k}.\n",
    "     $$\n",
    "   - Update the new weights using the computed likelihoods:\n",
    "     $$\n",
    "     w^{posterior}_i = L(\\theta^{prior}_i | h_k; m_k, n_k) \\cdot W^{prior}_i.\n",
    "     $$\n",
    "   - Normalize the new weights:\n",
    "     $$\n",
    "     W^{posterior}_i = \\frac{w^{posterior}_i}{\\sum w^{posterior}_i}.\n",
    "     $$\n",
    "\n",
    "2. **Construct the Posterior Distribution**:\n",
    "   - The posterior distribution is defined by the prior values ($\\{\\theta^{posterior}_i\\} = \\{\\theta^{prior}_i\\}$) and the updated weights ($W^{posterior}_i$).\n",
    "   - A potential issue arises when many weights are close to zero, making the probability distribution less useful for subsequent steps. To address this, the Bayesian update procedure is typically followed by a resampling protocol.\n",
    "\n",
    "3. **Resampling Protocol**:\n",
    "   - Resampling occurs if the **effective sample size (ESS)** of the weights falls below a specified `threshold` multiplied by the number of `particles`. The ESS is calculated as (the `ess` function from **QQuantLib.AE.bayesian_ae** executes this computation):\n",
    "     $$\n",
    "     ESS = \\frac{\\left(\\sum_i W^{posterior}_i\\right)^2}{\\sum_i {W^{posterior}_i}^2}.\n",
    "     $$\n",
    "\n",
    "4. **Resampling Procedure**:\n",
    "   - New $\\theta^{posterior}$ values are selected from the prior $\\theta^{prior}$ based on the probabilities given by their associated posterior weights ($W^{posterior}_i$).\n",
    "   - This process eliminates $\\theta$ values with very low weights and duplicates those with higher weights.\n",
    "\n",
    "5. **Apply Perturbation Kernel**:\n",
    "   - A perturbation kernel is applied to the resampled $\\theta^{posterior}$ values to introduce slight variations around the original values. Two kernel methods are supported:\n",
    "     - **Liu-West Kernel**: Set the `kernel` attribute to `\"LW\"` and configure the `alpha_lw` parameter appropriately (a value between 0 and 1).\n",
    "     - **Metropolis Kernel**: Set the `kernel` attribute to `\"Metro\"` and configure the `c` parameter appropriately (a value of 2.38 often works well).\n",
    "\n",
    "6. **Reset Weights After Resampling**:\n",
    "   - If resampling takes place, the new weights are reset to a uniform distribution:\n",
    "     $$\n",
    "     W^{posterior}_i = \\frac{1}{\\text{particles}}.\n",
    "     $$\n",
    "\n",
    "This process ensures that the posterior distribution remains robust and well-distributed for subsequent iterations of the algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09203d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QQuantLib.AE.bayesian_ae import bayesian_update, ess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11194ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first update the SMC posterior without allowing resampling\n",
    "\n",
    "theta_posterior, weights_posterior = bayesian_update(\n",
    "    theta_prior, weights_prior, # prior SMC \n",
    "    control_list, shots_list, outcome_list, # QAE experiment until the moment\n",
    "    resample=False, # Not resampliing\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e70a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(theta_prior, weights_prior, 'o')\n",
    "plt.plot(theta_posterior, weights_posterior, 'o')\n",
    "plt.legend([\"SMC prior\", \"SMC posterior\"])\n",
    "plt.xlabel(r\"$\\theta$\")\n",
    "plt.ylabel(r\"Weights($W$)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d22d7d9",
   "metadata": {},
   "source": [
    "As can be observed, there are many $\\theta$ values with weights close to zero. The **effective sample size (ESS)** can be used to determine whether resampling is necessary. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36788d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resampling needed: {}\".format(ess(weights_posterior) < bayes.threshold * bayes.particles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91197db7",
   "metadata": {},
   "source": [
    "If resampling is determined to be necessary, we can specify which kernel should be used for perturbing the resampled particles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d2bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liu-West Kernel\n",
    "lw_conf = {\"kernel\" : \"LW\", \"alpha_lw\" : bayes.alpha_lw}\n",
    "theta_posterior_lw, weights_posterior_lw = bayesian_update(\n",
    "    theta_prior, weights_prior, # prior SMC \n",
    "    [m_0], [bayes.warm_shots], [warm_outcome], # QAE experiment until the moment\n",
    "    resample=True, # Not resampling\n",
    "    **lw_conf\n",
    ")\n",
    "#Metropoli Kernel\n",
    "metro_conf = {\"kernel\" : \"Metro\", \"c\" : bayes.c}\n",
    "theta_posterior_metro, weights_posterior_metro = bayesian_update(\n",
    "    theta_prior, weights_prior, # prior SMC \n",
    "    [m_0], [bayes.warm_shots], [warm_outcome], # QAE experiment until the moment\n",
    "    resample=True, # Not resampling\n",
    "    **metro_conf\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9308cb",
   "metadata": {},
   "source": [
    "Now, we can visualize how the different kernels impact the SMC posterior probability distribution. By plotting the results, we can observe the effects of the perturbation introduced by each kernel on the resampled particles. This allows us to compare the behavior of the **Liu-West** and **Metropolis** kernels and understand their influence on the final distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6849a1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(theta_prior)\n",
    "plt.hist(theta_posterior_lw, alpha=0.8)\n",
    "plt.hist(theta_posterior_metro, alpha=0.8)\n",
    "plt.legend([\"Prior\", \"Posterior LW\", \"Posterior Metro\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f80a35",
   "metadata": {},
   "source": [
    "It is important to remember that when resampling is performed, the weights of the particles are reinitialized to have equal probabilities. This ensures that all resampled particles contribute equally to the subsequent steps of the algorithm, maintaining a balanced representation of the probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f383d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(theta_posterior_lw, weights_posterior_lw, 'o')\n",
    "plt.plot(theta_posterior_metro, weights_posterior_metro, 'o')\n",
    "plt.legend([\"LW\", \"Metro\"])\n",
    "plt.xlabel(r\"$\\theta$\")\n",
    "plt.ylabel(r\"Weights($W$)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af03e5c",
   "metadata": {},
   "source": [
    "Now that we have the SMC posterior distribution ($\\{\\theta^{posterior}_i\\}$ and $\\{W^{posterior}_i\\}$), we can estimate the desired parameter ($a$ or $\\theta$) by computing the **expected value of the mean** under the SMC posterior distribution.\n",
    "\n",
    "In the **SMC** framework, the expected value of any function $f$ under an SMC distribution is computed as follows:\n",
    "$$\n",
    "E_{\\theta, W}\\left[f(x)\\right] = \\sum_i f(\\theta^{posterior}_i) W^{posterior}_i\n",
    "$$\n",
    "\n",
    "Thus, the desired parameter estimation, $a$, can be computed as:\n",
    "\n",
    "$$\n",
    "\\hat{a} = \\sum_i \\sin^2(\\theta^{posterior}_i) W_i^{posterior}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b12207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use Metro Kernel results\n",
    "theta_posterior, weights_posterior = theta_posterior_metro, weights_posterior_metro\n",
    "# Computing the estimations\n",
    "a_estimation = (np.sin(theta_posterior) ** 2) @ weights_posterior\n",
    "print(\"Estimation of the a: {}. Real a value: {}\".format(a_estimation, a_good))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163e2ed1",
   "metadata": {},
   "source": [
    "The confidence interval for a given confidence level $\\alpha$ can be computed using the SMC posterior distribution. The confidence interval $\\left[\\theta^{\\alpha}_l, \\theta^{\\alpha}_u\\right]$ is defined such that:\n",
    "\n",
    "$$\n",
    "P_{\\theta, W}[\\theta > \\theta^{\\alpha}_l \\; \\text{and} \\; \\theta < \\theta^{\\alpha}_u] \\geq 1.0 - \\alpha\n",
    "$$\n",
    "\n",
    "This confidence interval serves as the **stopping condition** for the algorithm. Specifically, we require the size of the confidence interval to be smaller than an input threshold $\\epsilon$ (specified via the `epsilon` keyword):\n",
    "\n",
    "$$\n",
    "\\left|a^{\\alpha}_u - a^{\\alpha}_l\\right| < \\frac{\\epsilon}{2}\n",
    "$$\n",
    "\n",
    "Here, $a^{\\alpha}_{u, l}$ is derived from the bounds of the confidence interval for $\\theta$ as follows:\n",
    "$$\n",
    "a^{\\alpha}_{u, l} = \\sin^2{\\theta^{\\alpha}_{u, l}}\n",
    "$$\n",
    "\n",
    "The confidence interval can be computed using the `confidence_intervals` function from the **QQuantLib.AE.bayesian_ae** module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919b8327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QQuantLib.AE.bayesian_ae import confidence_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9dde61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cofidence level: {}\".format(bayes.alpha))\n",
    "theta_l, theta_u = confidence_intervals(theta_posterior, weights_posterior, bayes.alpha)\n",
    "a_l = np.sin(theta_l) ** 2\n",
    "a_u = np.sin(theta_u) ** 2\n",
    "print(\"confidence inteval: ({}, {})\".format(a_l, a_u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb86fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sin(theta_posterior) ** 2)\n",
    "plt.axvline(a_l, c=\"r\")\n",
    "plt.axvline(a_u, c=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d92d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenght_interval = np.abs(a_u-a_l)\n",
    "print(\"The length of the confidence interval for confidence level {} is: {}\".format(\n",
    "    bayes.alpha, lenght_interval,\n",
    "))\n",
    "print(\"The desired epsilon is: {}\".format(bayes.epsilon))\n",
    "print(\"Stop condition: {}\".format(lenght_interval < bayes.epsilon))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0148ccb8",
   "metadata": {},
   "source": [
    "#### 2.5.4 Improving Estimation Using Grover Circuits\n",
    "\n",
    "The **BAYESQAE** algorithm now begins to iteratively use Grover circuits to refine the estimation. In each iteration, the algorithm computes an optimal control $m^{*}_k$ based on the SMC posterior distribution from the previous iteration (i.e., the posterior distribution from the previous iteration becomes the prior distribution for the current iteration). The algorithm then performs a **Quantum Amplitude Estimation (QAE)** experiment with $m^{*}_k$ and updates the SMC posterior probability using the results. These iterations continue until the stopping condition is satisfied.\n",
    "\n",
    "The workflow for iteration $k$ is as follows:\n",
    "\n",
    "1. **Convert Old Posterior into New Priors**:\n",
    "   - Set $\\theta^{prior}_{i,k} \\leftarrow \\theta^{posterior}_{i, k-1}$.\n",
    "   - Set $W^{prior}_{i, k} \\leftarrow W^{posterior}_{i, k-1}$.\n",
    "\n",
    "2. **Compute Optimal Control**:\n",
    "   - Compute the optimal control $m^*_k$ using $\\theta^{prior}_{i,k}$, $W^{prior}_{i,k}$, and the results of all **QAE** experiments performed up to iteration $k$.\n",
    "\n",
    "3. **Execute QAE Experiment**:\n",
    "   - Perform the **QAE** experiment: $\\mathcal{Q}^{m^*_k}|\\Psi\\rangle$, using $n_k$ shots, and obtain the number of good states measured: $o_k$.\n",
    "\n",
    "4. **Update SMC Posterior Probability**:\n",
    "   - Use the `bayesian_update` function to update the SMC posterior probability:\n",
    "     $$\n",
    "     \\theta^{prior}_{i,k}, W^{prior}_{i,k}, m^*_k, n_k, o_k \\rightarrow \\theta^{posterior}_{i, k}, W^{posterior}_{i, k}.\n",
    "     $$\n",
    "\n",
    "5. **Check Stopping Condition**:\n",
    "   - Evaluate whether the stopping condition is satisfied. If not, return to step 1; otherwise, terminate the algorithm.\n",
    "\n",
    "This iterative process ensures that the estimation progressively improves until the desired precision is achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa4be65",
   "metadata": {},
   "source": [
    "#### 2.5.5 Computing the Optimal Control\n",
    "\n",
    "From the workflow presented in the previous section, the only step that remains to be explained is the second one: **Compute Optimal Control**.\n",
    "\n",
    "Before diving into this step, we need an important ingredient: a function that computes the **Utility of an experiment** for a given control $m_k$ and an input SMC probability distribution.\n",
    "\n",
    "---\n",
    "\n",
    "##### Utility of an Experiment\n",
    "\n",
    "The **Utility of an experiment** is computed using the following formula:\n",
    "\n",
    "$$\n",
    "U^{f}(m_k) = \\sum_{D} E_{P(\\theta)}[P(D; m_k)] \\cdot E_{P(\\theta|D, m_k)}[f(\\theta, D; m_k)]\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $f$: An input utility function defined by the user (keyword argument: `utility_function`). In the original paper, this is typically the variance\n",
    "- $E_{P(\\theta)}[P(D; m_k)]$: The probability of obtaining the outcome $D$ for a **QAE** experiment with control $m_k$. This is computed using Bayes' rule:\n",
    "  - $E_{P(\\theta)}[P(D; m_k)] = \\int L(\\theta|D; m_k) P(\\theta) d\\theta$\n",
    "  - $L(\\theta|D; m_k)$: The likelihood of obtaining the outcome $D$ for a **QAE** experiment with control $m_k$.\n",
    "  - If the input SMC probability is given by $\\{\\theta^{prior}_i, W^{prior}_i\\}$, this computation simplifies to:\n",
    "    $$\n",
    "    E_{P(\\theta)}[P(D; m_k)] = \\sum_i L(\\theta^{prior}_i|D; m_k) W^{prior}_i\n",
    "    $$\n",
    "\n",
    "- $E_{P(\\theta|D, m_k)}[f(\\theta, D; m_k)]$: The expected value of the *utility function* for an outcome $D$ of a **QAE** experiment with control $m_k$.\n",
    "  - If the input SMC probability is given by $\\{\\theta^{prior}_i, W^{prior}_i\\}$, the computation involves performing a hypothetical Bayesian update to compute the corresponding posterior distribution $\\{\\theta^{posterior}_i, W^{posterior}_i\\}$ using the possible outcome $D$ from a **QAE** experiment with control $m_k$.\n",
    "     $$\n",
    "     \\theta^{prior}_{i}, W^{prior}_{i}, m_k, D \\rightarrow \\theta^{posterior}_{i}, W^{posterior}_{i}.\n",
    "     $$  \n",
    "  - The computation is done as follows:\n",
    "    $$\n",
    "    E_{P(\\theta|D, m_k)}[f(\\theta, D; m_k)] = \\sum_i f(\\theta^{posterior}_i) \\cdot W^{posterior}_i\n",
    "    $$\n",
    "\n",
    "---\n",
    "\n",
    "To compute the **utility of the experiment** ($U^{f}(m_k)$), the `average_expectation` function from the **QQuantLib.AE.bayesian_ae** module is used. This function accepts the following inputs:\n",
    "- `thetas`: The values of the SMC prior distribution ($\\{\\theta^{prior}_i\\}$).\n",
    "- `weights`: The weights of the SMC prior distribution ($\\{W^{prior}_i\\}$).\n",
    "- `m_k`: A possible input control $m_k$.\n",
    "- `n_k`: The number of shots $n_k$ for a hypothetical **QAE** experiment.\n",
    "- `kwargs`: Other keyword arguments (It must have the `utility_function` one, that pass a python function)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7a4f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QQuantLib.AE.bayesian_ae import average_expectation, variance_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a991bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_k = 2\n",
    "n_k = 1\n",
    "conf_u = {\"utility_function\": variance_function}\n",
    "utility = average_expectation(\n",
    "    theta_posterior, weights_posterior, m_k, n_k, **conf_u\n",
    ")\n",
    "print(\"For m_k:{} and n_k:{} the utility will be: {}\".format(\n",
    "    m_k, n_k, utility\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad79242f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_k = 10\n",
    "n_k = 1\n",
    "conf_u = {\"utility_function\": variance_function}\n",
    "utility = average_expectation(\n",
    "    theta_posterior, weights_posterior, m_k, n_k, **conf_u\n",
    ")\n",
    "print(\"For m_k:{} and n_k:{} the utility will be: {}\".format(\n",
    "    m_k, n_k, utility\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cc0603",
   "metadata": {},
   "source": [
    "##### Control Optimization Using the **Utility**\n",
    "\n",
    "The **Utility of an experiment** is used to compute the **Optimal Control** for the next iteration. This is achieved by minimizing the **Utility of an experiment** over a predefined control domain. The `optimize_control` method of the `BAYESQAE` class performs this minimization and outputs the optimal control $m^*_k$.\n",
    "\n",
    "Initially, the predefined control domain is initialized to the interval $\\left[m_{min}, m_{max}\\right]$, where:\n",
    "- $m_{min} = 0$\n",
    "- $m_{max} = k_0 \\cdot n_{evals}$\n",
    "\n",
    "Here, $k_0$ and $n_{evals}$ are hyperparameters of the algorithm. The **Utility of an experiment** is computed for $n_{evals}$ possible controls within this interval, and the $m^*_k$ that minimizes it is selected.\n",
    "\n",
    "However, as the algorithm progresses through multiple iterations, the initial domain interval may no longer provide a suitable minimum for the **Utility of an experiment**. In such cases, it becomes necessary to enlarge the control domain interval. This enlargement is controlled by two hyperparameters: $R$ and $T$.\n",
    "\n",
    "- Each time the selected $m^*_k$ falls within the top $R$ tested controls, an internal counter is incremented by one.\n",
    "- When the counter reaches the threshold $T$, the control domain interval is enlarged by setting:\n",
    "  - $m_{min} \\leftarrow m_{max}$\n",
    "  - $m_{max} \\leftarrow 2 \\cdot m_{max}$\n",
    "- The internal counter is reset to zero, and the iteration process continues using the new control domain interval for computing $m^*_k$.\n",
    "\n",
    "---\n",
    "\n",
    "### Inputs of the `optimize_control` Method:\n",
    "- `thetas`: The values of the SMC prior distribution ($\\{\\theta^{prior}_i\\}$).\n",
    "- `weights`: The weights of the SMC prior distribution ($\\{W^{prior}_i\\}$).\n",
    "- `control_bayes_shots`: The number of shots used for the hypothetical **QAE** experiment required to compute the minimum of the **Utility** of an experiment. In the original paper, this is set to 1.\n",
    "- `kwargs`: Keyword arguments for configuring the `optimize_control` method:\n",
    "  - `n_evals`: Number of evaluations ($n_{evals}$) for testing controls within the domain.\n",
    "  - `k_0`: Scaling factor ($k_0$) for initializing the control domain.\n",
    "  - `R`: Threshold for determining when the selected $m^*_k$ is among the top tested controls.\n",
    "  - `T`: Counter threshold for triggering the enlargement of the control domain interval.\n",
    "  - `utility_function`: Base function for computing the **Utility of an experiment**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee3ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the last step SMC posterior probability for computing new \n",
    "\n",
    "# Configure the optimal control\n",
    "conf = {\n",
    "    \"R\": bayes.R, \"T\": bayes.T, \"k_0\": bayes.k_0, \"n_evals\": bayes.n_evals,\n",
    "    \"utility_function\": bayes.utility_function\n",
    "}\n",
    "# Control for next iteration\n",
    "optimal_control = bayes.optimize_control(\n",
    "    theta_posterior, weights_posterior, \n",
    "    bayes.control_bayes_shots, **conf\n",
    ")\n",
    "print(\"The optimal control for the following iteration is: {}\".format(optimal_control))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee2267e",
   "metadata": {},
   "source": [
    "The attributes `m_min` and `m_max` of the `BAYESQAE` object store the interval for the domain control ($m_{min}$ and $m_{max}$).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80e1080",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Domain interval control: [{}, {}]\".format(bayes.m_min, bayes.m_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ced731f",
   "metadata": {},
   "source": [
    "Now, we can iteratively execute the workflow presented in Section 2.5.5 until the desired `epsilon` is achieved. \n",
    "\n",
    "The following cell can be run multiple times until the stopping condition is satisfied. Each execution refines the estimation by updating the SMC posterior distribution and computing a new optimal control $m_k^*$, bringing the algorithm closer to the desired precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce5c0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps 1 and 2 of section 2.5.5\n",
    "optimal_control = bayes.optimize_control(\n",
    "    theta_posterior, weights_posterior, \n",
    "    bayes.control_bayes_shots, **conf\n",
    ")\n",
    "print(\"The optimal control for the following iteration is: {}\".format(optimal_control))\n",
    "print(\"Domain interval control: [{}, {}]\".format(bayes.m_min, bayes.m_max))\n",
    "# Step 3 of section 2.5.5\n",
    "p_m, routine = bayes.quantum_measure_step(\n",
    "    optimal_control, bayes.shots\n",
    ")\n",
    "\n",
    "control_list.append(optimal_control)\n",
    "shots_list.append(bayes.shots)\n",
    "outcome_list.append(round(p_m * bayes.shots))\n",
    "# Step 4 of section 2.5.5\n",
    "theta_posterior, weights_posterior = bayesian_update(\n",
    "    theta_posterior, weights_posterior,\n",
    "    control_list, shots_list, outcome_list, **metro_conf\n",
    "\n",
    ")    \n",
    "# Step 5 of section 2.5.5\n",
    "a_estimation = (np.sin(theta_posterior) ** 2) @ weights_posterior\n",
    "theta_l, theta_u = confidence_intervals(theta_posterior, weights_posterior, bayes.alpha)\n",
    "a_l = np.sin(theta_l) ** 2\n",
    "a_u = np.sin(theta_u) ** 2\n",
    "print(\"Estimation of the a: {}. \\n\\t confidence inteval: ({}, {})\".format(\n",
    "    a_estimation, a_l, a_u)\n",
    ")\n",
    "\n",
    "stop_condition = (a_u-a_l) < 2 * bayes.epsilon\n",
    "print(\"Stop condition: {}\".format(stop_condition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635dee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Absolute Error: {}\".format(np.abs(a_estimation-a_good)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f985e603",
   "metadata": {},
   "source": [
    "We can plot the final SMC posterior probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4080a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sin(theta_posterior)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d45150",
   "metadata": {},
   "source": [
    "## 3. Complete Execution of BAYESQAE\n",
    "\n",
    "Section 2 provided a detailed explanation of the **BAYESQAE** algorithm, with an emphasis on the inner workings and the use of various functions and methods from **QQuantLib.AE.bayesian_ae** for pedagogical purposes. The `BAYESQAE` class encapsulates the entire workflow described in Section 2, abstracting away the complexities and providing a user-friendly interface.\n",
    "\n",
    "For a complete **BAYESQAE** execution, users are expected to interact with only the following methods:\n",
    "- `bayesqae`\n",
    "- `run`\n",
    "\n",
    "The following sub sections explain them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a15610",
   "metadata": {},
   "source": [
    "### 3.1 The `bayesqae` Method\n",
    "\n",
    "To execute the complete **BAYESQAE** algorithm, the `bayesqae` method is used. The user must first initialize the class by providing the minimum mandatory inputs (`oracle`, `target`, and `index`). It is recomended too provided info about the quantum part of the algorithm (keyword `qpu`). Once the class is initialized, the `bayesqae` method can be executed by supplying a Python dictionary containing all the necessary configuration parameters.\n",
    "\n",
    "This approach allows users to provide a comprehensive set of inputs in a single step, ensuring that the algorithm is fully configured before execution. The method handles the entire workflow internally, abstracting away the complexities of the underlying processes.\n",
    "\n",
    "This method populates the following attributes:\n",
    "\n",
    "- `mean_a`: evolution of the expected value of the mean throughout the entire algorithm's execution.\n",
    "- `lower_a`: evolution of the lower value for confidence interval throughout the entire algorithm's execution.\n",
    "- `upper_a`: evolution of the upper value for confidence interval throughout the entire algorithm's execution.\n",
    "- `control_list`: evolution of the different controls used for the **QAE** experiments performed throughout the entire algorithm's execution.\n",
    "- `shots_list`: number of shots used for the **QAE** experiments performed throughout the entire algorithm's execution.\n",
    "- `outcome_list`: evolution of the different outcomes from the **QAE** experiments performed throughout the entire algorithm's execution.\n",
    "- `pdf_theta`: evolution of the probability distribution values throughout the entire algorithm's execution.\n",
    "- `pdf_weights`: evolution of the probability distribution weights throughout the entire algorithm's execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25cf6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate the Class\n",
    "\n",
    "# It is recomeded to initialize the quantum part when the class is instantiated\n",
    "qpu_conf = {\n",
    "    # Quantum parts related\n",
    "    'qpu': linalg_qpu,\n",
    "}\n",
    "\n",
    "bayes = BAYESQAE(\n",
    "    oracle,\n",
    "    target=target,\n",
    "    index=index,\n",
    "    **qpu_conf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd2ad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shots\n",
    "shots = 1\n",
    "#Stoping condition of the algorithm\n",
    "epsilon = 1.0e-3\n",
    "alpha = 0.05\n",
    "\n",
    "bayes_conf = {\n",
    "    # Stoping condition\n",
    "    \"epsilon\" : epsilon,\n",
    "    \"alpha\": alpha,\n",
    "    \"max_iterations\": 1000,\n",
    "    # Configuration of the SMC method\n",
    "    \"particles\": 2000,      \n",
    "    \"threshold\": 0.5,    \n",
    "    \"kernel\" : \"LW\", #\"Metro\", #LW\n",
    "    \"alpha_lw\":0.9, # Liu-West kernel configuration\n",
    "    \"c\" : 2.38,   # Metropoli kernel configuration \n",
    "    # Dinamyc evolution of the domain controls\n",
    "    \"k_0\":2, \n",
    "    \"T\" : 3,\n",
    "    \"R\" : 3,    \n",
    "    \"n_evals\" : 50,    \n",
    "    # Shots configuration\n",
    "    \"shots\" : shots,\n",
    "    \"warm_shots\":10,\n",
    "    \"bayes_shots\": shots,\n",
    "    \"control_bayes_shots\" : shots,\n",
    "    # Fake configuration\n",
    "    \"fake\": False,\n",
    "    \"theta_good\": theta_good,    \n",
    "    # Other configuration\n",
    "    \"save_smc_prob\" : 1,\n",
    "    \"print_info\" : 1,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b47baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_mean, a_l, a_u = bayes.bayesqae(**bayes_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90524ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Estimation: {}. Confidence intervals: [{},{}]\".format(\n",
    "    a_mean, a_l, a_u\n",
    "))\n",
    "print(\"Error: {}\".format(abs(a_mean-a_good)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6feb3a2",
   "metadata": {},
   "source": [
    "\n",
    "The class attributes `mean_a`, `lower_a`, and `upper_a` store the evolution of the expected value of the mean and the confidence intervals throughout the entire algorithm's execution. These attributes provide insight into how the estimates for $a$ improve iteratively as the **BAYESQAE** algorithm progresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eee08b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(bayes.lower_a, '-o')\n",
    "plt.plot(bayes.mean_a, '-o')\n",
    "plt.plot(bayes.upper_a, '-o')\n",
    "plt.legend([\"a_l\", \"a_mean\", \"a_u\"])\n",
    "plt.ylabel(r\"a\")\n",
    "plt.xlabel(\"iteration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aff1a2",
   "metadata": {},
   "source": [
    "Additionally, the attributes `outcome_list`, `control_list`, and `shots_list` store the details of the different **QAE** experiments performed during the algorithm's execution. These attributes provide a record of the outcomes, controls, and shot configurations used in each experiment, allowing for a detailed analysis of the algorithm's behavior and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffc26d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes.outcome_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef97c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes.control_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cfaeac",
   "metadata": {},
   "source": [
    "The class attributes `pdf_theta` and `pdf_weights` are Pandas DataFrames that store the SMC probability distribution (values and weights, respectively) at various stages of the algorithm's iterations. The frequency with which these distributions are saved is controlled by the keyword argument `save_smc_prob`. This allows users to analyze the evolution of the SMC probability distribution over time, providing insights into how the algorithm refines its estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4e95a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes.pdf_theta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0942875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes.pdf_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788b2bc2",
   "metadata": {},
   "source": [
    "The following cell generates an animation illustrating the evolution of the SMC probability distribution across different iterations of the algorithm. This visualization provides insight into how the distribution refines and converges as the **BAYESQAE** process progresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80ded2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_theta = bayes.pdf_theta\n",
    "%matplotlib notebook\n",
    "from matplotlib.animation import FuncAnimation\n",
    "fig, ax = plt.subplots()\n",
    "def update(frame):\n",
    "    \n",
    "    # Limpiar el eje para evitar superposiciÃ³n\n",
    "    ax.cla()\n",
    "    \n",
    "    # Seleccionar la columna correspondiente al cuadro actual\n",
    "    column_name = pdf_theta.columns[frame]\n",
    "    data = pdf_theta[column_name]\n",
    "    \n",
    "    # Dibujar el histograma\n",
    "    #ax.hist(pdf_theta[\"prior\"], bins=20, edgecolor='black')\n",
    "    ax.hist(data, bins=20, color='skyblue', edgecolor='black')\n",
    "    \n",
    "    # AÃ±adir tÃ­tulo y etiquetas\n",
    "    ax.set_title(f'Histograma of {column_name}')\n",
    "    #ax.set_xlabel('Valores')\n",
    "    #ax.set_ylabel('Frecuencia')\n",
    "    \n",
    "    # Devolver el eje\n",
    "    return ax\n",
    "# NÃºmero de frames igual al nÃºmero de columnas\n",
    "num_frames = len(pdf_theta.columns)\n",
    "ani = FuncAnimation(fig, update, frames=num_frames, interval=1000, repeat=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f10d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ae58ec",
   "metadata": {},
   "source": [
    "We can update the input dictionary and perform the algorithm again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85de817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the shots\n",
    "bayes_conf.update({\n",
    "    \"shots\" : 1000,\n",
    "    \"warm_shots\":100,\n",
    "    \"bayes_shots\": 100,\n",
    "    \"control_bayes_shots\" : 1,\n",
    "    \"epsilon\" : 1.0e-4,        \n",
    "})\n",
    "a_mean, a_l, a_u = bayes.bayesqae(**bayes_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d504f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use fake binomial sampling for simulating quantum step\n",
    "bayes_conf.update({\n",
    "    \"shots\" : 1,\n",
    "    \"warm_shots\":1,\n",
    "    \"bayes_shots\": 1,\n",
    "    \"control_bayes_shots\" : 1,\n",
    "    \"epsilon\" : 1.0e-10,   \n",
    "    \"save_smc_prob\" : 10,\n",
    "    \"print_info\" : 10,  \n",
    "    \"fake\":True\n",
    "})\n",
    "a_mean, a_l, a_u = bayes.bayesqae(**bayes_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aced85bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(bayes.lower_a, '-o')\n",
    "plt.plot(bayes.mean_a, '-o')\n",
    "plt.plot(bayes.upper_a, '-o')\n",
    "plt.legend([\"a_l\", \"a_mean\", \"a_u\"])\n",
    "plt.ylabel(r\"a\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a047199d",
   "metadata": {},
   "source": [
    "### 3.1 The `run` Method\n",
    "\n",
    "The `run` method executes the **BAYESQAE** algorithm directly using the configuration provided during the instantiation of the `BAYESQAE` class or the default configuration if none is specified. This method automates the entire workflow, handling all intermediate steps and iterations until the stopping condition is satisfied.\n",
    "\n",
    "Upon completion, the `run` method populates the following attributes:\n",
    "\n",
    "- `ae` :  final exepected mean value of the parameter $a$ (computed using the final posterior distribution)\n",
    "- `ae_l` :  final lower value of the confidence interval for aprameter $a$ (computed using the final posterior distribution)\n",
    "- `ae_u`:  final upper value of the confidence interval for aprameter $a$ (computed using the final posterior distribution)\n",
    "- `schedule_pdf`: A Pandas DataFrame that summarizes the **QAE** experiments and their results performed during the execution of the algorithm.\n",
    "- `oracle_calls`: The total number of oracle calls made during the complete execution of the algorithm, accounting for the number of shots used in each experiment.\n",
    "- `max_oracle_depth`: The maximum number of applications of the oracle during the execution of the algorithm (not accounting for shots). This indicates the depth of the largest quantum circuit used.\n",
    "- `pdf_estimation`: A Pandas DataFrame that tracks the evolution of the mean estimation and the upper and lower bounds of the confidence intervals throughout the algorithm's execution.\n",
    "- `run_time`: the elapsed time of the complete **BAYESQAE** algorithm\n",
    "- `quantum_time`: total time the algorithm expends in the pure quantum part.\n",
    "\n",
    "These attributes provide valuable insights into the performance and behavior of the algorithm, enabling users to analyze its efficiency and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af50aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shots\n",
    "shots = 1\n",
    "#Stoping condition of the algorithm\n",
    "epsilon = 1.0e-4\n",
    "alpha = 0.05\n",
    "\n",
    "bayes_conf = {\n",
    "    'qpu': linalg_qpu,    \n",
    "    # Stoping condition\n",
    "    \"epsilon\" : epsilon,\n",
    "    \"alpha\": alpha,\n",
    "    \"max_iterations\": 1000,\n",
    "    # Configuration of the SMC method\n",
    "    \"particles\": 2000,      \n",
    "    \"threshold\": 0.5,    \n",
    "    \"kernel\" : \"LW\", #\"Metro\", #LW\n",
    "    \"alpha_lw\":0.9, # Liu-West kernel configuration\n",
    "    \"c\" : 2.38,   # Metropoli kernel configuration \n",
    "    # Dinamyc evolution of the domain controls\n",
    "    \"k_0\":2, \n",
    "    \"T\" : 3,\n",
    "    \"R\" : 3,    \n",
    "    \"n_evals\" : 50,    \n",
    "    # Shots configuration\n",
    "    \"shots\" : shots,\n",
    "    \"warm_shots\":10,\n",
    "    \"bayes_shots\": shots,\n",
    "    \"control_bayes_shots\" : 1,\n",
    "    # Fake configuration\n",
    "    \"fake\": False,\n",
    "    \"theta_good\": theta_good,    \n",
    "    # Other configuration\n",
    "    \"save_smc_prob\" : 10,\n",
    "    \"print_info\" : 10,    \n",
    "}\n",
    "bayes = BAYESQAE(\n",
    "    oracle,\n",
    "    target=target,\n",
    "    index=index,\n",
    "    **bayes_conf\n",
    ")\n",
    "a_estimated = bayes.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622892aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(bayes.lower_a, '-o')\n",
    "plt.plot(bayes.mean_a, '-o')\n",
    "plt.plot(bayes.upper_a, '-o')\n",
    "plt.legend([\"a_l\", \"a_mean\", \"a_u\"])\n",
    "plt.ylabel(r\"a\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d594c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('a_estimated: ', a_estimated)\n",
    "print('Real Value of a: ', a_good)\n",
    "print('Bounds for a: [bayes.ae_l, bayes.ae_u] = [{}, {}]'.format(bayes.ae_l, bayes.ae_u))\n",
    "print('Estimated a: bayes.ae = ', bayes.ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b155f319",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' a_real-iqbayesae.ae: ', abs(bayes.ae-a_good))\n",
    "print('Epsilon required: ', bayes.epsilon)\n",
    "print('Bayes lenght of confidence intervals ', 0.5 * (bayes.ae_u-bayes.ae_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9285d1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total number of oracle calls\n",
    "print(\"The total number of the oracle calls was: {}\".format(bayes.oracle_calls))\n",
    "#Total number of oracle calls\n",
    "print(\"The maximum depth oracle circuit was: {}\".format(bayes.max_oracle_depth))\n",
    "\n",
    "print(\"Elapsed time for the run method: \", bayes.run_time)\n",
    "print(\"Time of the quantum parts: \", bayes.quantum_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace1b447",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(bayes.quantum_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb013bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bayes.schedule_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cd0352",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bayes.pdf_estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7365adbf",
   "metadata": {},
   "source": [
    "Finally we can use the evolution of the **QAE** experiments, `schedule_pdf`, and the evolution of the $a$ estimations, `pdf_estimation`, to plot the evolution of the error ($\\epsilon$) of the estimation versus the number of calls ($N_A$) to the oracle and compare with MonteCarlo behaviour, $\\epsilon = \\frac{1}{\\sqrt{N_A}}$, and with the Heisenberg limit $\\epsilon = \\frac{1}{N_A}$\n",
    "\n",
    "Finally, we can utilize the evolution of the **QAE** experiments (`schedule_pdf`) and the evolution of the $a$ estimations (`pdf_estimation`) to plot the relationship between the estimation error ($\\epsilon$) and the number of oracle calls ($N_A$). This allows us to compare the performance of the **BAYESQAE** algorithm with two benchmark behaviors:\n",
    "- The **Monte Carlo behavior**, where $\\epsilon = \\frac{1}{\\sqrt{N_A}}$.\n",
    "- The **Heisenberg limit**, where $\\epsilon = \\frac{1}{N_A}$.\n",
    "\n",
    "This comparison provides insight into the efficiency and convergence rate of the **BAYESQAE** algorithm relative to classical and quantum limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb90038",
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_calls_ev = (bayes.schedule_pdf[\"m_k\"] * 2 + 1) * bayes.schedule_pdf[\"shots\"].cumsum()\n",
    "error_ev = np.abs(bayes.pdf_estimation[\"mean\"] - a_good)\n",
    "\n",
    "plt.plot(\n",
    "    oracle_calls_ev, \n",
    "    error_ev,\n",
    "    'o'\n",
    ")\n",
    "\n",
    "domain_oracle = np.linspace(oracle_calls_ev.min(), oracle_calls_ev.max())\n",
    "\n",
    "plt.plot(\n",
    "    domain_oracle, \n",
    "    np.sqrt(1.0/domain_oracle),\n",
    "    '-'\n",
    ")\n",
    "plt.plot(\n",
    "    domain_oracle, \n",
    "    1.0/domain_oracle,\n",
    "    '-'\n",
    ")\n",
    "\n",
    "plt.xlabel(r\"Oracle Calls ($N_A$)\")\n",
    "plt.ylabel(r\"Absolute Error (\\epsilon)\")\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend([\"BAYESQAE\", r\"$\\epsilon = \\frac{1}{\\sqrt{N_{A}}}$\", r\"$\\epsilon = \\frac{1}{N_{A}}$\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

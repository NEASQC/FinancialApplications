{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "855eaacd",
   "metadata": {},
   "source": [
    "# Evaluating PQCs\n",
    "\n",
    "To train the **PQCS** (see notebook *16_qml4var_BuildPQC.ipynb*) using a dataset (see *15_qml4var_DataSets.ipynb*) it is mandatory to design a workflow that evaluates the **PQC**, for a fixed set of trainable parameters $\\theta$, in the input features of the dataset.\n",
    "\n",
    "Present notebook reviews the mandatory functions for building this workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce8ae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import json\n",
    "sys.path.append(\"../../\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a28bfd",
   "metadata": {},
   "source": [
    "## 1. Get some dataset\n",
    "\n",
    "First, some dataset for evaluating the **PQC** is needed. A random dataset will be generated using the *create_random_data* from **benchmark.qml4var.data_sets** module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c70982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark.qml4var.data_sets import create_random_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ae863",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_random = {\n",
    "    \"n_points_train\": 10, \n",
    "    \"n_points_test\" : 100,\n",
    "    \"minval\" : -np.pi,\n",
    "    \"maxval\" : np.pi,\n",
    "    \"features_number\" : 1\n",
    "}\n",
    "x_train, y_train, x_test, y_test = create_random_data(\n",
    "    **cfg_random\n",
    ")\n",
    "plt.plot(x_train, y_train, \"o\")\n",
    "plt.plot(x_test, y_test, \"-\")\n",
    "plt.xlabel(\"Domain\")\n",
    "plt.ylabel(\"CDF\")\n",
    "plt.legend([\"Training Dataset\", \"Testing Dataset\"])\n",
    "plt.title(\"Random Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6076cc55",
   "metadata": {},
   "source": [
    "## 2. Build the PQC\n",
    "\n",
    "The *hardware_efficient_ansatz* and the *z_observable* from **QQuantLib.qml4var.architectures** modules will be used to build the **PQC**. Additionally, the *normalize_data* function will be used for data normalization between $\\frac{-\\pi}{2}$ and $\\frac{\\pi}{2}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789e6bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QQuantLib.qml4var.architectures import hardware_efficient_ansatz, z_observable, normalize_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2e5743",
   "metadata": {},
   "outputs": [],
   "source": [
    "pqc_cfg = {\n",
    "    \"features_number\" : cfg_random[\"features_number\"],\n",
    "    \"n_qubits_by_feature\" : 2,\n",
    "    \"n_layers\": 3    \n",
    "}\n",
    "# Normalization function\n",
    "base_frecuency, shift_feature = normalize_data(\n",
    "    [cfg_random[\"minval\"]] * cfg_random[\"features_number\"],\n",
    "    [cfg_random[\"maxval\"]] * cfg_random[\"features_number\"],\n",
    "    [-0.5*np.pi] * cfg_random[\"features_number\"],\n",
    "    [0.5*np.pi] * cfg_random[\"features_number\"]   \n",
    ")\n",
    "pqc_cfg.update({\n",
    "    \"base_frecuency\" : base_frecuency,\n",
    "    \"shift_feature\" : shift_feature    \n",
    "})   \n",
    "print(pqc_cfg)\n",
    "pqc, weights_names, features_names = hardware_efficient_ansatz(**pqc_cfg)\n",
    "observable = z_observable(**pqc_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81150b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PQC\n",
    "circuit = pqc.to_circ()\n",
    "circuit.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01655939",
   "metadata": {},
   "source": [
    "## 3. PQC single evaluation using stack of Plugins\n",
    "\n",
    "This sections explains how to evaluate the **PQC** ($F^*(\\textbf{x}, \\theta)$), for a fixed set of weights, $\\theta$, for a single input $\\tilde{\\textbf{x}}$. So we want to compute: $F^*(\\tilde{\\textbf{x}}, \\theta)$.\n",
    "\n",
    "A function that executes the following workflow is needed:\n",
    "\n",
    "1. Assigns the $\\theta$ to the **weights**  parameters of the **PQC**.\n",
    "2. Assings the input sample $\\tilde{\\textbf{x}}$ to the **features** parameters of the **PQC**\n",
    "3. Execute (or simulate) the obtained quantum circuit\n",
    "4. Return the expected value of the  **PQC** under the desired **Observable**.\n",
    "\n",
    "To implement this workflow in **EVIDEN myqlm** we will use the stack of Plugins concept. \n",
    "\n",
    "The stack is a complete set of **myQLM Plugins (https://myqlm.github.io/02_user_guide/02_execute/04_plugin.html)**  that can process a flow of quantum jobs on their way to **Quantum Process Unit (QPU)** and/or process a flow of information (samples or values) on their way back from a **QPU**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5b6837",
   "metadata": {},
   "source": [
    "### 3.1 QPU configuration\n",
    "\n",
    "To build a complete **myqlm Pluging stack** a **myqlm QPU** is mandatory. The following cells show how to configure and instantiate a **myqlm QPU** (see *00_AboutTheNotebooksAndQPUs*).\n",
    "\n",
    "Here we use a JSON configuration file found in the **benchmark/qml4var/JSONs/** folder of the *FinancialApplications* software package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9db4566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QQuantLib.utils.benchmark_utils import combination_for_list\n",
    "from QQuantLib.qpu.select_qpu import select_qpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6428a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "json_qpu = \"../../benchmark/qml4var/JSONs/qpu_ideal.json\"\n",
    "with open(json_qpu) as json_file:\n",
    "    qpu_dict = json.load(json_file)\n",
    "qpu_list = combination_for_list(qpu_dict)\n",
    "qpu_dict = qpu_list[0]\n",
    "print(qpu_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e03c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the QPU\n",
    "qpu = select_qpu(qpu_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b978d756",
   "metadata": {},
   "source": [
    "### 3.2 Building the Plugin stack\n",
    "\n",
    "To build the stack of **myqlm Plugins** we are going to use different homemade Plugins found in the **QQuantLib.qml4var.plugins** module.\n",
    "\n",
    "\n",
    "The *SetParametersPlugin* plugin is the most important one because it allows us to fix the *weights* and the *features* for all the **PQC**s from a Batch of myqlm jobs.\n",
    "\n",
    "Additionally, we are going to use the *ViewPlugin* that allows to print the circuits in one part of the stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce3f887",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from QQuantLib.qml4var.plugins import SetParametersPlugin, ViewPlugin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497c62f7",
   "metadata": {},
   "source": [
    "The *SetParametersPlugin* needs as inputs the desired weights and the features for evaluating the **PQC**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f60d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some random weights\n",
    "weights_ = [np.random.rand() for w in weights_names]\n",
    "print(\"weights_: {}\".format(weights_))\n",
    "# print select a input for evaluating the PQC\n",
    "sample_ = x_train[0]\n",
    "print(\"sample_: {}\".format(sample_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5547ba1",
   "metadata": {},
   "source": [
    "Now the plugin stack will be built by including the QPU object at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472507dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_ = SetParametersPlugin(weights_, sample_) | ViewPlugin(\"SetParametersPlugin\") | qpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbec042",
   "metadata": {},
   "source": [
    "### 3.3 Execute the Pluging stack\n",
    "\n",
    "Finally, we can use the built stack to evaluate a **Batch** of **myQLM Jobs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc701bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qat.core import Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c22cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first: build quantum circuit from PQC\n",
    "circuit = pqc.to_circ()\n",
    "#second: build the job with the observable\n",
    "job = circuit.to_job(nbshots=0, observable=observable)\n",
    "#third: build the Batch of jobs with the observable\n",
    "batch_ = Batch(jobs=[job])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b41e453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input circuit\n",
    "circuit.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78908816",
   "metadata": {},
   "source": [
    "To properly use the built stack (with the *SetParametersPlugin*) on a **myQLM Batch**, some information must be provided. In this case, it is mandatory to indicate which parameters of the PQC are related to the **weights** and which are related to the input **features**.\n",
    "\n",
    "This information should be provided as a Python dictionary to the *meta_data* attribute of the batch, as shown in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e7870",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_.meta_data = {\n",
    "    \"weights\" : weights_names, # PQC parameters related with weights\n",
    "    \"features\" : features_names # PQC parameters related with features\n",
    "}\n",
    "#fourth using stack to execute the batch_\n",
    "results = stack_.submit(batch_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2784817d",
   "metadata": {},
   "source": [
    "In the preceding cell, the *ViewPlugin* plots the quantum circuit resulting from the SetParametersPlugin. As can be seen, this plugin has replaced the parameters of the initial quantum circuit with the ones provided to the plugin.\n",
    "\n",
    "The evaluation of the job can be found in the *value* attribute of the corresponding **myQLM Result** (the first one in this case) within the returned **myQLM BatchResult**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa3f2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For weights: {}\".format(weights_))\n",
    "print(\"And for input :{}\".format(sample_))\n",
    "print(\"The evaluation of the PQC is: {}\".format(results[0].value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e20bd1",
   "metadata": {},
   "source": [
    "Python lambda functions can be used to add more versatility to the plugins!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cbfc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First the weights and features can be passed as lambda input variables\n",
    "# Second the complete stack is built\n",
    "stack_2 = lambda weights, features: \\\n",
    "    SetParametersPlugin(weights, features) | qpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b77281",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Evaluation for: {} is {}\".format(\n",
    "    x_train[2], \n",
    "    stack_2(weights_, x_train[2]).submit(batch_)[0].value\n",
    "))\n",
    "print(\"Evaluation for: {} is {}\".format(\n",
    "    x_train[4], \n",
    "    stack_2(weights_, x_train[4]).submit(batch_)[0].value\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644f2bb8",
   "metadata": {},
   "source": [
    "### 3.4 Building stack for PDF evaluation (the pdfPluging Plugin)\n",
    "\n",
    "We can extend the plugin stack to easily evaluate the **PDF** of an input **PQC**.\n",
    "\n",
    "As explained in *16_qml4var_BuildPQC*, in addition to a **PQC** for computing the **CDF**, $F^*(\\textbf{x}, \\theta)$, our training workflow will also need to compute the corresponding **PDF** of the **CDF**:\n",
    "\n",
    "\n",
    "$$f^*(\\textbf{x}, \\theta) = \\frac{\\partial^m F^*(\\textbf{x}, \\theta)}{\\partial x_{m-1} \\cdots \\partial x_1 \\partial x_0}$$\n",
    "\n",
    "In the notebook *16_qml4var_BuildPQC*, the *compute_pdf_from_pqc* function from the **QQuantLib.qml4var.architectures** module was used to generate the quantum circuits required for computing this **PDF**.\n",
    "\n",
    "Here, we will take a different approach: we will build a new stack of plugins that includes the *pdfPlugin* from the **QQuantLib.qml4var.plugins** module. This *pdfPlugin* converts *compute_pdf_from_pqc* into a **myQLM Plugin** that can be added to a stack. The resulting stack will generate all the necessary quantum circuits for computing the desired **PDF**.\n",
    "\n",
    "The *pdfPlugin* requires the **PQC** feature names as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346b7d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QQuantLib.qml4var.plugins import pdfPluging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1b3432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the stack for PDF computations\n",
    "# Here we use the ViewPlugin to see the quantum circuits mandatory for PDF computation\n",
    "stack_pdf = lambda weights, features: \\\n",
    "    pdfPluging(features_names) | ViewPlugin(\"pdfPluging\") | SetParametersPlugin(weights, features) | qpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1e74c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pdf = stack_pdf(weights_, sample_).submit(batch_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fe29c1",
   "metadata": {},
   "source": [
    "As can be seen, the *ViewPlugin* allows us to see which quantum circuits should be generated for building **PDF** evaluation.\n",
    "\n",
    "As usual, the output of the stack_execution is a **myQLM BatchResult**. The value attribute of the first element of the **BatchResult** contains the desired **PDF** value. In the *meta_data* attribute, we can see the measurements for all the built circuits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b11cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The evaluation of the PDF  using the PQC for the input {} is {}\".format(\n",
    "    sample_, result_pdf[0].value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5676c8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The evaluation of all the generated circuits:\\n {}\".format(result_pdf[0].meta_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3b5821",
   "metadata": {},
   "source": [
    "## 4. The myqlm_workflows module\n",
    "\n",
    "The **QQuantLib.qml4var.myqlm_workflows** module is the central module used for building the different workflows mandatory for building a complete training process for **PQC**s.\n",
    "\n",
    "This module contains several functions that allows to the user build the workflow for evaluating quantum circuits in **myQLM** using the concepts of a stack of plugins easily.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fddb64d",
   "metadata": {},
   "source": [
    "### 4.1 The stack_execution Function\n",
    "\n",
    "The *stack_execution* function from **QQuantLib.qml4var.myqlm_workflows** is the central function of this module and automates the previously described workflow for a given plugin stack.\n",
    "\n",
    "The main inputs of the function are:\n",
    "\n",
    "* weights : The weights for the **PQC** ($\\theta$).\n",
    "* x_sample : The desired sample input ($\\tilde{\\textbf{x}}$).\n",
    "* stack : A group of myQLM plugins that enables **PQC** evaluation. \n",
    "* kwargs : Keyword arguments with additional information. Mandatory  keywords:\n",
    "    * pqc: The value MUST BE the **myQLM Program** that implements the desired PQC.\n",
    "    * observable: The value MUST BE the **myQLM Observable** for the PQC.\n",
    "    * weights_names: The value MUST BE a list of all the parameter names of the **PQC** related to the weights.\n",
    "    * features_names: The value MUST BE a list of all the parameter names of the **PQC** related to the features.\n",
    "    * nbshots: The number of shots for evaluating the **PQC**.\n",
    "    \n",
    "The return of the **stack_execution** will be a **myQLM BatchResult**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee7829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QQuantLib.qml4var.myqlm_workflows import stack_execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca0e1f8",
   "metadata": {},
   "source": [
    "To the *stack_execution* a properly configured stack should be provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5185b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbshots = 0\n",
    "# Configuring the workflow\n",
    "workflow_cfg = {\n",
    "    \"pqc\" : pqc,\n",
    "    \"observable\" : observable,\n",
    "    \"weights_names\" : weights_names,\n",
    "    \"features_names\" : features_names,\n",
    "    \"nbshots\" : nbshots,\n",
    "}\n",
    "# The stack for computing CDF is sending to the stack_execution function\n",
    "result = stack_execution(weights_, sample_, stack_2, **workflow_cfg)\n",
    "print(\"The evaluation of the PQC for the input {} is {}\".format(sample_, result[0].value))\n",
    "print(\"When the weights of the PQC were fixed to: {}\".format(weights_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefc52db",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbshots = 0\n",
    "# Configuring the workflow\n",
    "workflow_cfg = {\n",
    "    \"pqc\" : pqc,\n",
    "    \"observable\" : observable,\n",
    "    \"weights_names\" : weights_names,\n",
    "    \"features_names\" : features_names,\n",
    "    \"nbshots\" : nbshots,\n",
    "}\n",
    "# The stack for computing PDF is sending to the stack_execution function\n",
    "result = stack_execution(weights_, sample_, stack_pdf, **workflow_cfg)\n",
    "print(\"The evaluation of the PQC for the input {} is {}\".format(sample_, result[0].value))\n",
    "print(\"When the weights of the PQC were fixed to: {}\".format(weights_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acd9103",
   "metadata": {},
   "source": [
    "### 4.2 the cdf_workflow Function\n",
    "\n",
    "The *cdf_workflow* function, from **QQuantLib.qml4var.myqlm_workflows** module, automates the complete mandatory workflow for evaluating a **PQC**. This function selects the **QPU** (by providing the configuration), builds the desired **myQLM** stack, and submits the generated batch to it. The main inputs of the function are:\n",
    "\n",
    "* weights: The weights for the **PQC**.\n",
    "* x_sample: The desired sample input ($\\vec{x}$).\n",
    "* kwargs: Keyword arguments with additional information. Mandatory keywords:\n",
    "    * *pqc*: The value MUST BE the **myQLM Program** that implements the desired **PQC**.\n",
    "    * *observable*: The value MUST BE **myQLM Observable** for the **PQC**.\n",
    "    * *weights_names*: The value MUST BE a list with the names of all the parameters of the **PQC** related to the **weights**.\n",
    "    * *features_names*: The value MUST BE a list with the names of all the parameters of the **PQC** related to the **features**.\n",
    "    * *nbshots*: The number of shots for evaluating the **PQC**\n",
    "    * *qpu_info*: QPU configuration dictionary\n",
    "    \n",
    "The return of the function is the evaluation of the PQC using the provided features and weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171eecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QQuantLib.qml4var.myqlm_workflows import cdf_workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f51d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_cfg = {\n",
    "    \"pqc\" : pqc,\n",
    "    \"observable\" : observable,\n",
    "    \"weights_names\" : weights_names,\n",
    "    \"features_names\" : features_names,\n",
    "    \"nbshots\" : nbshots,\n",
    "    \"qpu_info\" : qpu_dict\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5a4b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_ = cdf_workflow(weights_, sample_, **workflow_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679c0f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The evaluation of the PQC for the input {} is {}\".format(sample_, value_))\n",
    "print(\"When the weights of the PQC were fixed to: {}\".format(weights_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e199a53c",
   "metadata": {},
   "source": [
    "### 4.2 the pdf_workflow Function\n",
    "\n",
    "The *pdf_workflow* function, from **QQuantLib.qml4var.qlm_procces** module, automates the complete mandatory workflow for evaluating the **PDF** of a given **PQC**. This function selects the **QPU** (by providing the configuration), builds the desired QLM stack, and submits the generated batch to it. The main inputs of the function are:\n",
    "\n",
    "* weights: The weights for the **PQC**.\n",
    "* x_sample: The desired sample input ($\\vec{x}$).\n",
    "* kwargs: Keyword arguments with additional information. Mandatory keywords:\n",
    "    * *pqc*: The value MUST BE the **myQLM Program** that implements the desired **PQC**.\n",
    "    * *observable*: The value MUST BE **myQLM Observable** for the **PQC**.\n",
    "    * *weights_names*: the value MUST BE a list with the names of all the parameters of the **PQC** related to the **weights**.\n",
    "    * *features_names*: the value MUST BE a list with the names of all the parameters of the **PQC** related to the **features**.\n",
    "    * *nbshots* : The number of shots for evaluating the **PQC**.\n",
    "    * *qpu_info* : **QPU** configuration dictionary\n",
    "    \n",
    "The return of the function is the evaluation of the **PDF** using the provided **features** and **weights**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14ff2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QQuantLib.qml4var.myqlm_workflows  import pdf_workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3367bf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_pdf = pdf_workflow(weights_, sample_, **workflow_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644236b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a4b6fc",
   "metadata": {},
   "source": [
    "In the following cells the *cdf_workflow* and the *pdf_workflow* are used for a more complex **PQC** architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6865b7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test PQC\n",
    "test_pqc_dict = {\n",
    "    'features_number': 2,\n",
    "    'n_qubits_by_feature': 3,\n",
    "    'n_layers': 4, \n",
    "}\n",
    "\n",
    "# Get Normalization function\n",
    "test_base_frecuency, test_shift_feature =normalize_data(\n",
    "    [-np.pi] * test_pqc_dict[\"features_number\"],\n",
    "    [np.pi] * test_pqc_dict[\"features_number\"],\n",
    "    [-0.5*np.pi] * test_pqc_dict[\"features_number\"],\n",
    "    [0.5*np.pi] * test_pqc_dict[\"features_number\"],    \n",
    ")\n",
    "# Update with the normalization\n",
    "test_pqc_dict.update({\n",
    "    \"base_frecuency\" : test_base_frecuency,\n",
    "    \"shift_feature\" : test_shift_feature\n",
    "})\n",
    "# Create test pqc\n",
    "test_pqc, test_weights_names, test_features_names = hardware_efficient_ansatz(\n",
    "    **test_pqc_dict\n",
    ")\n",
    "# Create test Observable\n",
    "test_observable = z_observable(**test_pqc_dict)\n",
    "\n",
    "test_workflow_cfg = {\n",
    "    \"pqc\" : test_pqc,\n",
    "    \"observable\" : test_observable,\n",
    "    \"weights_names\" : test_weights_names,\n",
    "    \"features_names\" : test_features_names,\n",
    "    \"nbshots\" : 0,\n",
    "    \"qpu_info\" : qpu_dict    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "test_circuit = test_pqc.to_circ()\n",
    "test_circuit.display()\n",
    "\n",
    "weights_test = [np.random.rand() for w in test_weights_names]\n",
    "data_test = np.array([[-0.5, 0.2]])\n",
    "sample_test = data_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b9c8cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "value_cdf_test = cdf_workflow(weights_test, sample_test, **test_workflow_cfg)\n",
    "print(\"CDF _evaluation: {}\".format(value_cdf_test))\n",
    "value_pdf_test = pdf_workflow(weights_test, sample_test, **test_workflow_cfg)\n",
    "print(\"PDF _evaluation: {}\".format(value_pdf_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7f2471",
   "metadata": {},
   "source": [
    "### 4.3 The workflow_execution function\n",
    "\n",
    "Now we need to compute the **CDF** and the **PDF** for all the samples in the dataset, given a complete input dataset (i.e., ${\\tilde{\\textbf{x}}^j, j=0, 1, \\cdots, m-1}$, where $m$ is the number of samples in the dataset).\n",
    "\n",
    "To do this, the *workflow_execution* function from the **QQuantLib.qml4var.myqlm_workflows** module can be used. This function receives the **weights**, the complete input dataset, and a properly configured workflow (such as *cdf_workflow* or *pdf_workflow*) to compute the corresponding evaluations of the **CDF** or the **PDF** using the **PQC**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b7362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QQuantLib.qml4var.myqlm_workflows import workflow_execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d35e1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First configure porperly the desired workflow computation\n",
    "\n",
    "# for computing CDF using PQC\n",
    "cdf_workflow_ = lambda w,x : cdf_workflow(w, x, **workflow_cfg)\n",
    "# for computing PDF using PQC\n",
    "pdf_workflow_ = lambda w,x : pdf_workflow(w, x, **workflow_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cac18e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cdf_prediction = workflow_execution(weights_, x_train, cdf_workflow_)\n",
    "pdf_prediction = workflow_execution(weights_, x_train, pdf_workflow_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71db48b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc874685",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea1c802",
   "metadata": {},
   "source": [
    "#### Using a Dask client. \n",
    "\n",
    "When the number of samples in the input dataset is high the evaluation can be time-consuming. If the user has access to a Dask cluster these evaluations can be submitted to the cluster in parallel achieving a high speed up. For doing this the only thing to do is provide the Dask client to the *workflow_execution*. In this case, the return are a list of *futures* so a list should provided to the gather method of the dask client to retrieve the desired result\n",
    "\n",
    "**BE AWARE**\n",
    "\n",
    "The following cells should be executed only if a Dask cluster is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05459f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client\n",
    "path_to_schedule_json = \"/home/cesga/gferro/Codigo/qlm_cVar/dask_cluster_ft3/scheduler_info.json\"\n",
    "#path_to_schedule_json = \"/home/cesga/gferro/Codigo/dask_cluster_ft3/scheduler_info.json\"\n",
    "client = Client(\n",
    "    scheduler_file = path_to_schedule_json,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a1d463",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cdf_prediction_fut = workflow_execution(weights_, x_train, cdf_workflow_, client)\n",
    "pdf_prediction_fut = workflow_execution(weights_, x_train, pdf_workflow_,client)\n",
    "cdf_prediction_ = client.gather(cdf_prediction_fut)\n",
    "pdf_prediction_ = client.gather(pdf_prediction_fut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0ed874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a list of futures\n",
    "cdf_prediction_fut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb326cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the result of gather the futures so this is the desired result\n",
    "cdf_prediction_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dc57a1",
   "metadata": {},
   "source": [
    "###  4.4 *workflow_for_cdf* and *workflow_for_pdf* functions.\n",
    "\n",
    "The *workflow_for_cdf* and *workflow_for_pdf* functions from **QQuantLib.qml4var.myqlm_workflows** build the before presented workflows for computing respectively **CDF** and **PDF** straightforwardly. \n",
    "\n",
    "The inputs are:\n",
    "\n",
    "* weights: numpy array with weights for PQC ($\\theta$)\n",
    "* data_x: numpy array with dataset of the features\n",
    "* kwargs: keyword arguments:\n",
    "    * *pqc*: The value MUST BE the **myQLM Program** that implements the desired **PQC**.\n",
    "    * *observable*: The value MUST BE **myQLM Observable** for the **PQC**.\n",
    "    * *weights_names*: the value MUST BE a list with the names of all the parameters of the **PQC** related to the **weights**.\n",
    "    * *features_names*: the value MUST BE a list with the names of all the parameters of the **PQC** related to the **features**.\n",
    "    * *nbshots* : The number of shots for evaluating the **PQC**.\n",
    "    * *qpu_info* : **QPU** configuration dictionary\n",
    "\n",
    "The output will be a Python dictionary with the results:\n",
    "\n",
    "* The *workflow_for_cdf* output will have a key *y_predict_cdf* with the desired results.\n",
    "* The *workflow_for_pdf* output will have a key *y_predict_pdf* with the desired results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba80338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QQuantLib.qml4var.myqlm_workflows import workflow_for_cdf, workflow_for_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a259dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf_value = workflow_for_cdf(weights_, x_train, **workflow_cfg)\n",
    "pdf_value = workflow_for_pdf(weights_, x_train, **workflow_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cb0712",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cdf_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aeba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pdf_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58408af0",
   "metadata": {},
   "source": [
    "#### 4.2.1 Using a DASK cluster\n",
    "\n",
    "To the arguments of the *workflow_for_cdf* and *workflow_for_pdf* functions a *DASK* client can be provided to speed up the computations. In this case,  the computations will be sent to the *DASK* cluster and the results retrieved transparently for the user.\n",
    "\n",
    "**BE AWARE**\n",
    "\n",
    "The following cells should be executed only if a Dask cluster is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceef2ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf_value_dask = workflow_for_cdf(weights_, x_train, dask_client=client, **workflow_cfg)\n",
    "pdf_value_dask = workflow_for_pdf(weights_, x_train, dask_client=client, **workflow_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09b2019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now the results are not futures anymore, they are the desired numpy array\n",
    "cdf_value_dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b2192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_value_dask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
